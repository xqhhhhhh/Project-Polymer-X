# Project Polymer-X 系统设计

## 目标与规模
- 监控 500 个化工网站的每日更新
- 每日新增文本 10GB
- 需要高并发抓取、稳定解析、增量清洗、持续产出结构化与训练数据

## 架构概述
分布式爬虫 + 流批结合清洗流水线，核心组件：Scrapy-Redis、Kafka、Spark、Airflow、对象存储、元数据中心。

```
┌───────────────┐     ┌───────────────┐     ┌─────────────────┐
│ 站点配置库     │     │ 任务调度器     │     │ 代理池/UA服务    │
│ (YAML/DB)     │───▶│ Airflow        │───▶│ 反爬与封禁检测    │
└───────────────┘     └───────────────┘     └─────────────────┘
         │                    │
         ▼                    ▼
┌──────────────────────────────────────────────────────┐
│         分布式爬虫集群 (Scrapy-Redis)                  │
│  - URL 队列/去重 (Redis)                               │
│  - 并发抓取 + 断点续传                                 │
│  - JS 渲染池 (Playwright/Selenium)                     │
└──────────────────────────────────────────────────────┘
         │
         ▼
┌───────────────────────┐      ┌──────────────────────┐
│ 原始数据落盘           │      │ 实时消息队列          │
│ (S3/MinIO/HDFS)        │◀────│ Kafka raw-topic      │
└───────────────────────┘      └──────────────────────┘
         │                               │
         ▼                               ▼
┌──────────────────────────────────────────────────────┐
│                 清洗与解析集群 (Spark)                │
│  - HTML/PDF 解析                                      │
│  - Schema 对齐/单位换算                               │
│  - 数据校验/异常检测                                 │
└──────────────────────────────────────────────────────┘
         │
         ▼
┌───────────────────────┐      ┌──────────────────────┐
│ 结构化数据仓库          │      │ 训练数据构建服务      │
│ (Delta/Iceberg)        │───▶  │ JSONL/Alpaca 输出    │
└───────────────────────┘      └──────────────────────┘
         │                               │
         ▼                               ▼
┌───────────────────────┐      ┌──────────────────────┐
│ 监控与告警              │      │ 数据质量平台          │
│ Prometheus/Grafana     │      │ 规则 + 统计分析       │
└───────────────────────┘      └──────────────────────┘
```

## 关键设计点
1. **高并发抓取**：Scrapy-Redis 统一调度与去重，节点水平扩容，吞吐可控。
2. **动态渲染**：JS-heavy 站点进入渲染池，Playwright 集群独立扩缩容。
3. **断点续传**：URL 队列持久化 + 下载状态表，失败重试与回补任务。
4. **反爬策略**：IP 池、UA 轮换、Header 指纹、多线路出口与限速策略。
5. **解析容错**：解析失败进入死信队列，人工回放与规则迭代。
6. **Schema 对齐**：字段字典 + 单位换算服务，所有清洗结果统一入仓。
7. **数据质量**：范围校验 + 脏数据日志 + 质量指标报表。

## 调度与扩展策略
- Airflow 按站点分组调度，热门站点增量抓取，长尾站点低频批处理。
- Kafka 作为原始数据缓冲，Spark Streaming 清洗高频数据，批处理兜底。
- 解析规则与模型结合：规则优先，模型补抽取与纠错。
- 资源按任务分组弹性伸缩，控制峰值成本。
